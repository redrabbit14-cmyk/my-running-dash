import streamlit as st
import requests
import os
from datetime import datetime, timedelta
import pandas as pd
from PIL import Image
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ëŸ¬ë‹ í¬ë£¨ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸƒ",
    layout="wide"
)

# í™˜ê²½ ì„¤ì •
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
DATABASE_ID = os.environ.get("DATABASE_ID")

# Notion API í—¤ë”
headers = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

@st.cache_data(ttl=3600)
def fetch_notion_data():
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    
    all_results = []
    has_more = True
    start_cursor = None
    
    while has_more:
        payload = {}
        if start_cursor:
            payload["start_cursor"] = start_cursor
            
        response = requests.post(url, headers=headers, json=payload)
        
        if response.status_code != 200:
            st.error(f"ë…¸ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            st.error(f"ì—ëŸ¬ ë©”ì‹œì§€: {response.text}")
            return pd.DataFrame()
        
        data = response.json()
        all_results.extend(data.get("results", []))
        has_more = data.get("has_more", False)
        start_cursor = data.get("next_cursor")
    
    st.info(f"ë…¸ì…˜ì—ì„œ {len(all_results)}ê°œì˜ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    return parse_notion_data(all_results)

def parse_notion_data(results):
    """ë…¸ì…˜ ë°ì´í„° íŒŒì‹±"""
    records = []
    
    st.write(f"íŒŒì‹± ì‹œì‘: {len(results)}ê°œ í•­ëª©")
    
    for idx, page in enumerate(results):
        props = page["properties"]
        
        try:
            # ì œëª© (ë¹ˆ ë¬¸ìì—´ ì»¬ëŸ¼) - ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ
            title_prop = props.get("", {}).get("title", [])
            name = title_prop[0].get("text", {}).get("content", "") if title_prop else f"Run-{idx}"
            
            # ë‚ ì§œ
            date_obj = props.get("ë‚ ì§œ", {}).get("date", {})
            date_str = date_obj.get("start", "") if date_obj else ""
            
            # ê±°ë¦¬ (ì‹¤ì œ ê±°ë¦¬) - formula íƒ€ì…
            distance_prop = props.get("ì‹¤ì œ ê±°ë¦¬", {})
            if distance_prop.get("type") == "formula":
                distance = distance_prop.get("formula", {}).get("number")
            else:
                distance = distance_prop.get("number")
            
            # í˜ì´ìŠ¤
            pace_prop = props.get("í˜ì´ìŠ¤", {}).get("rich_text", [])
            pace_text = pace_prop[0].get("text", {}).get("content", "0") if pace_prop else "0"
            
            # ê³ ë„
            elevation_prop = props.get("ê³ ë„", {})
            if elevation_prop.get("type") == "formula":
                elevation = elevation_prop.get("formula", {}).get("number", 0)
            else:
                elevation = elevation_prop.get("number", 0)
            
            # ì‹œê°„ (runners)
            time_prop = props.get("runners", {}).get("rich_text", [])
            time_text = time_prop[0].get("text", {}).get("content", "0") if time_prop else "0"
            
            # ì‚¬ëŒ
            people = props.get("ì‚¬ëŒ", {}).get("people", [])
            person_name = people[0].get("name", "") if people else ""
            person_avatar = people[0].get("avatar_url", "") if people else ""
            
            # name ì¡°ê±´ ì œê±°, dateì™€ distanceë§Œ í™•ì¸
            if date_str and distance:
                records.append({
                    "name": name,
                    "date": date_str,
                    "distance": distance,
                    "pace": pace_text,
                    "elevation": elevation if elevation else 0,
                    "time": float(time_text) if time_text else 0,
                    "person_name": person_name,
                    "person_avatar": person_avatar
                })
        except Exception as e:
            st.warning(f"íŒŒì‹± ì—ëŸ¬ (í•­ëª© {idx}): {str(e)}")
            continue
    
    st.write(f"íŒŒì‹± ì™„ë£Œ: {len(records)}ê°œ ë ˆì½”ë“œ")
    
    df = pd.DataFrame(records)
    
    if df.empty:
        st.error("DataFrameì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return df
    
    df["date"] = pd.to_datetime(df["date"])
    
    df = df.drop_duplicates(subset=["name", "date", "distance"], keep="first")
    
    df["pace_numeric"] = df["pace"].apply(lambda x: float(str(x).replace(",", "")) if x else 0)
    
    st.success(f"ìµœì¢… ë°ì´í„°: {len(df)}ê°œ ë ˆì½”ë“œ")
    
    return df.sort_values("date", ascending=False).reset_index(drop=True)

def get_week_range(date):
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ ì†í•œ ì£¼ì˜ ì›”ìš”ì¼ê³¼ ì¼ìš”ì¼ ë°˜í™˜"""
    weekday = date.weekday()
    monday = date - timedelta(days=weekday)
    sunday = monday + timedelta(days=6)
    return monday, sunday

def filter_by_week(df, week_offset=0):
    """week_offset: 0=ì´ë²ˆì£¼, -1=ì§€ë‚œì£¼"""
    today = datetime.now()
    target_date = today + timedelta(weeks=week_offset)
    monday, sunday = get_week_range(target_date)
    
    return df[(df["date"] >= monday) & (df["date"] <= sunday)]

def main():
    st.title("ğŸƒ ëŸ¬ë‹ í¬ë£¨ ëŒ€ì‹œë³´ë“œ")
    
    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        df = fetch_notion_data()
    
    if df.empty:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    this_week_df = filter_by_week(df, 0)
    last_week_df = filter_by_week(df, -1)
    
    st.header("ğŸ“Š í¬ë£¨ í˜„í™©")
    
    col1, col2, col3 = st.columns(3)
    
    this_week_total = this_week_df["distance"].sum()
    last_week_total = last_week_df["distance"].sum()
    
    if last_week_total > 0:
        change_pct = ((this_week_total - last_week_total) / last_week_total) * 100
    else:
        change_pct = 0
    
    with col1:
        st.metric("ì´ë²ˆ ì£¼ ì´ ê±°ë¦¬", f"{this_week_total:.1f} km")
    
    with col2:
        st.metric("ì§€ë‚œ ì£¼ ì´ ê±°ë¦¬", f"{last_week_total:.1f} km")
    
    with col3:
        st.metric("ì „ì£¼ ëŒ€ë¹„", f"{change_pct:+.1f}%", delta=f"{this_week_total - last_week_total:.1f} km")
    
    st.divider()
    
    st.header("ğŸ’ª í¬ë£¨ ì»¨ë””ì…˜")
    
    crew_members = ["ì¬íƒ", "ìœ ì¬", "ì£¼í˜„", "ìš©ë‚¨"]
    
    cols = st.columns(4)
    
    for idx, member in enumerate(crew_members):
        with cols[idx]:
            member_this_week = this_week_df[this_week_df["person_name"] == member]
            member_last_week = last_week_df[last_week_df["person_name"] == member]
            
            if not member_this_week.empty and member_this_week.iloc[0]["person_avatar"]:
                try:
                    avatar_url = member_this_week.iloc[0]["person_avatar"]
                    response = requests.get(avatar_url)
                    img = Image.open(BytesIO(response.content))
                    st.image(img, use_container_width=True)
                except:
                    st.image("https://via.placeholder.com/150", use_container_width=True)
            else:
                st.image("https://via.placeholder.com/150", use_container_width=True)
            
            st.markdown(f"### {member}")
            
            this_week_distance = member_this_week["distance"].sum()
            st.metric("ì´ë²ˆ ì£¼", f"{this_week_distance:.1f} km")
            
            last_week_distance = member_last_week["distance"].sum()
            st.metric("ì§€ë‚œ ì£¼", f"{last_week_distance:.1f} km")
            
            seven_days_ago = datetime.now() - timedelta(days=7)
            recent_7days = df[(df["person_name"] == member) & (df["date"] >= seven_days_ago)]
            
            if not recent_7days.empty and recent_7days["pace_numeric"].sum() > 0:
                avg_pace = recent_7days["pace_numeric"].mean()
                st.metric("í‰ê·  í˜ì´ìŠ¤", f"{avg_pace:.1f} ë¶„/km")
            else:
                st.metric("í‰ê·  í˜ì´ìŠ¤", "ê¸°ë¡ ì—†ìŒ")
    
    st.divider()
    
    st.header("ğŸ† Insight & Fun")
    
    if not this_week_df.empty:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸƒ ì´ ì£¼ì˜ ë§ˆë¼í† ë„ˆ")
            longest_run = this_week_df.loc[this_week_df["distance"].idxmax()]
            st.markdown(f"""
            **{longest_run['person_name']}**  
            {longest_run['distance']:.2f} km  
            {longest_run['date'].strftime('%Y-%m-%d')}
            """)
        
        with col2:
            st.subheader("â›°ï¸ ì´ ì£¼ì˜ ë“±ì‚°ê°€")
            highest_elevation = this_week_df.loc[this_week_df["elevation"].idxmax()]
            st.markdown(f"""
            **{highest_elevation['person_name']}**  
            {highest_elevation['elevation']:.0f} m  
            {highest_elevation['date'].strftime('%Y-%m-%d')}
            """)
        
        with col3:
            st.subheader("âš¡ ì´ ì£¼ì˜ í­ì£¼ê¸°ê´€ì°¨")
            valid_pace_df = this_week_df[this_week_df["pace_numeric"] > 0]
            if not valid_pace_df.empty:
                fastest_pace = valid_pace_df.loc[valid_pace_df["pace_numeric"].idxmin()]
                st.markdown(f"""
                **{fastest_pace['person_name']}**  
                {fastest_pace['pace_numeric']:.2f} ë¶„/km  
                {fastest_pace['date'].strftime('%Y-%m-%d')}
                """)
            else:
                st.info("í˜ì´ìŠ¤ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì´ë²ˆ ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.divider()
    if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

if __name__ == "__main__":
    main()
