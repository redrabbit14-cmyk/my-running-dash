import streamlit as st
import pandas as pd
import os
from datetime import datetime, timedelta
import requests

# 1. í™˜ê²½ ì„¤ì •
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
DATABASE_ID = os.environ.get("DATABASE_ID")

st.set_page_config(page_title="ëŸ¬ë‹ í¬ë£¨ ëŒ€ì‹œë³´ë“œ", layout="wide")

# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì—ëŸ¬ ë°©ì§€ìš©)
def mps_to_pace_str(mps):
    try:
        if mps is None or mps <= 0: return "N/A"
        total_seconds = 1000 / mps
        return f"{int(total_seconds // 60)}:{int(total_seconds % 60):02d}"
    except: return "N/A"

def pace_to_seconds(pace_str):
    try:
        if not pace_str or pd.isna(pace_str) or pace_str == "N/A": return None
        parts = str(pace_str).split(':')
        return int(float(parts[0]) * 60 + float(parts[1]))
    except: return None

def seconds_to_pace(seconds):
    try:
        if seconds is None or pd.isna(seconds) or seconds <= 0: return "N/A"
        return f"{int(seconds // 60)}:{int(seconds % 60):02d}"
    except: return "N/A"

# 3. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)
@st.cache_data(ttl=300) # 5ë¶„ë§ˆë‹¤ ê°±ì‹ 
def fetch_notion_data():
    try:
        response = requests.post(
            f"https://api.notion.com/v1/databases/{DATABASE_ID}/query",
            headers={"Authorization": f"Bearer {NOTION_TOKEN}", "Notion-Version": "2022-06-28", "Content-Type": "application/json"},
            json={"page_size": 100}
        )
        if response.status_code != 200:
            st.error(f"ë…¸ì…˜ ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
            return pd.DataFrame()

        results = response.json().get("results", [])
        data = []
        for row in results:
            props = row.get("properties", {})
            
            # í•„ìˆ˜ í•„ë“œ ì²´í¬ ë° ì•ˆì „í•œ ì¶”ì¶œ
            date_info = props.get("ë‚ ì§œ", {}).get("date")
            if not date_info: continue
            
            runner = props.get("ëŸ¬ë„ˆ", {}).get("select", {}).get("name", "Unknown")
            
            # ê±°ë¦¬ ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ëŒ€ì‘)
            dist_val = 0
            for f_name in ["ì‹¤ì œ ê±°ë¦¬", "ê±°ë¦¬", "Distance"]:
                val = props.get(f_name, {}).get("number")
                if val is not None:
                    dist_val = val if val < 100 else val / 1000
                    break
            
            # í˜ì´ìŠ¤ ë° ì‚¬ì§„ ì¶”ì¶œ
            mps = props.get("í˜ì´ìŠ¤", {}).get("number")
            
            photo_url = None
            files = props.get("ì‚¬ì§„", {}).get("files", [])
            if files:
                f_obj = files[0]
                photo_url = f_obj.get("file", {}).get("url") if f_obj.get("type") == "file" else f_obj.get("external", {}).get("url")

            data.append({
                "ë‚ ì§œ": date_info.get("start")[:10],
                "ëŸ¬ë„ˆ": runner, "ê±°ë¦¬": dist_val, "í˜ì´ìŠ¤": mps_to_pace_str(mps),
                "ì‚¬ì§„": photo_url
            })
        
        df = pd.DataFrame(data)
        if not df.empty:
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
            return df.sort_values('ë‚ ì§œ', ascending=False)
        return df
    except Exception as e:
        st.warning(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# --- í™”ë©´ ì¶œë ¥ ---
df = fetch_notion_data()
if df.empty:
    st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë…¸ì…˜ ì—°ê²°ì„ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.")
    st.stop()

st.title("ğŸƒ ëŸ¬ë‹ í¬ë£¨ ëŒ€ì‹œë³´ë“œ")

# ì£¼ê°„ ìš”ì•½ ê³„ì‚°
today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
this_week_start = today - timedelta(days=(today.weekday() + 1) % 7)
tw_df = df[df['ë‚ ì§œ'] >= this_week_start]

st.metric("ì´ë²ˆ ì£¼ í¬ë£¨ í•©ì‚° ê±°ë¦¬", f"{tw_df['ê±°ë¦¬'].sum():.2f} km")

# í¬ë£¨ ì¹´ë“œ (Streamlit ê¸°ë³¸ ì»¬ëŸ¼ ì‚¬ìš© - ê°¤ëŸ­ì‹œ S25ì—ì„œ ì„¸ë¡œë¡œ ë³´ì„)
crew_list = ["ìš©ë‚¨", "ì¬íƒ", "ì£¼í˜„", "ìœ ì¬"]
cols = st.columns(len(crew_list))

for i, member in enumerate(crew_list):
    with cols[i]:
        m_data = df[df['ëŸ¬ë„ˆ'] == member].head(7)
        
        # ê°€ì¤‘ í‰ê·  í˜ì´ìŠ¤ ê³„ì‚°
        avg_pace = "N/A"
        if not m_data.empty:
            m_data['p_sec'] = m_data['í˜ì´ìŠ¤'].apply(pace_to_seconds)
            valid = m_data.dropna(subset=['p_sec', 'ê±°ë¦¬'])
            if not valid.empty and valid['ê±°ë¦¬'].sum() > 0:
                avg_pace = seconds_to_pace((valid['p_sec'] * valid['ê±°ë¦¬']).sum() / valid['ê±°ë¦¬'].sum())
        
        # ì‚¬ì§„ ì¶œë ¥ (ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì•„ì´ì½˜)
        pic = m_data['ì‚¬ì§„'].dropna().iloc[0] if not m_data['ì‚¬ì§„'].dropna().empty else None
        if pic:
            st.image(pic, width=80)
        else:
            st.write("ğŸ‘¤")
            
        st.subheader(member)
        st.write(f"í˜ì´ìŠ¤: {avg_pace}")
        st.write(f"ì´ë²ˆì£¼: {tw_df[tw_df['ëŸ¬ë„ˆ']==member]['ê±°ë¦¬'].sum():.1f}km")
